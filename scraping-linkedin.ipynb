{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing packages (done)\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "print('Importing packages (done)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing a driver (done)\n",
      "Importing the login credentials (done)\n",
      "Input email (done)\n",
      "Input password (done)\n",
      "Login to Linkedin (done)\n"
     ]
    }
   ],
   "source": [
    "# Login to Linkedin\n",
    "\n",
    "# Open Chrome and Access Linkedin login site\n",
    "driver = webdriver.Chrome(\"C:/Users/guedri/Downloads/chromedriver_win32/chromedriver.exe\")\n",
    "sleep(2)\n",
    "url = 'https://www.linkedin.com/login'\n",
    "driver.get(url)\n",
    "print('Initializing a driver (done)')\n",
    "sleep(2)\n",
    "\n",
    "# Import username and password\n",
    "credential = open('credentials.txt')\n",
    "line = credential.readlines()\n",
    "username = line[0]\n",
    "password = line[1]\n",
    "print('Importing the login credentials (done)')\n",
    "sleep(2)\n",
    "\n",
    "# Input the login credentials\n",
    "email_field = driver.find_element_by_id('username')\n",
    "email_field.send_keys(username)\n",
    "print('Input email (done)')\n",
    "sleep(3)\n",
    "\n",
    "password_field = driver.find_element_by_name('session_password')\n",
    "password_field.send_keys(password)\n",
    "print('Input password (done)')\n",
    "sleep(2)\n",
    "\n",
    "# Click the Login button\n",
    "signin_field = driver.find_element_by_xpath('//*[@id=\"organic-div\"]/form/div[3]/button')\n",
    "signin_field.click()\n",
    "sleep(3)\n",
    "\n",
    "print('Login to Linkedin (done)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What profile do you want to scrape? oussema guedri\n",
      "Search for profiles (done)\n"
     ]
    }
   ],
   "source": [
    "# Search for the profiles we want to scrape\n",
    "\n",
    "# Locate the search bar element\n",
    "search_field = driver.find_element_by_xpath('//*[@class=\"search-global-typeahead__input always-show-placeholder\"]')\n",
    "\n",
    "# Input the search query to the search bar\n",
    "search_query = input('What profile do you want to scrape? ')\n",
    "search_field.send_keys(search_query)\n",
    "\n",
    "# Search\n",
    "search_field.send_keys(Keys.RETURN)\n",
    "\n",
    "print('Search for profiles (done)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many pages you want to scrape: 1\n",
      "['https://www.linkedin.com/in/oussema-guedri', 'https://www.linkedin.com/in/oussema-guedri-4b4b5262', 'https://www.linkedin.com/in/ACoAACnFaJ8BKdNenhXDV4xEEIleRdyTI3wxMLc', 'https://www.linkedin.com/in/ACoAAA1XCUgBupPoq4Yq9I1X2H-QZRUgvzWCISo']\n",
      "Scrape the URLs (done)\n"
     ]
    }
   ],
   "source": [
    "# Scrape the URLs of the profiles\n",
    "\n",
    "# A function to extract the URLs of one page\n",
    "def GetURL():\n",
    "    page_source = BeautifulSoup(driver.page_source)\n",
    "    profiles = page_source.find_all('a', class_ = 'app-aware-link')\n",
    "    all_profile_URL = []\n",
    "    for profile in profiles:\n",
    "        profile_URL = profile.get('href')\n",
    "        if \"https://www.linkedin.com/in/\" in profile_URL and \"/recent-activity/\" not in profile_URL:\n",
    "            if profile_URL not in all_profile_URL:\n",
    "                all_profile_URL.append(profile_URL)\n",
    "    return all_profile_URL\n",
    "\n",
    "# Navigate through many pages, and extract the profile URLs of each page\n",
    "\n",
    "input_page = int(input('How many pages you want to scrape: '))\n",
    "URLs_all_page = []\n",
    "\n",
    "if(input_page > 1):\n",
    "    for page in range(input_page):\n",
    "        URLs_one_page = GetURL()\n",
    "        sleep(2)\n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight);') #scroll to the end of the page\n",
    "        sleep(3)\n",
    "        next_button = driver.find_element_by_class_name('artdeco-pagination__button--next')\n",
    "        driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "        URLs_all_page = URLs_all_page + URLs_one_page\n",
    "        sleep(2)\n",
    "else:\n",
    "    URLs_one_page = GetURL()\n",
    "    sleep(2)\n",
    "    driver.execute_script('window.scrollTo(0, document.body.scrollHeight);') #scroll to the end of the page\n",
    "    sleep(3)\n",
    "    URLs_all_page = URLs_all_page + URLs_one_page\n",
    "    sleep(2)\n",
    "print(URLs_all_page)\n",
    "print('Scrape the URLs (done)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLs_all_page = ['https://www.linkedin.com/in/khaled-adrani/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing profile:  https://www.linkedin.com/in/khaled-adrani/\n",
      "Khaled ADRANI\n",
      "Talan Tunisie\n",
      "Ariana, Tunis, Tunisie\n",
      "Machine Learning Intern at Talan Tunisie\n",
      "[]\n",
      "['Machine Learning', 'Python', 'Data Science', 'Développement web', 'Writing', 'Data Visualization', 'Intelligence artificielle', 'Data Analysis', 'Java', 'JavaScript', 'Adobe Photoshop', 'HTML', 'Adobe Illustrator', 'C', 'Feuilles de style en cascade (CSS)', 'HTML5', 'Node.js', 'MongoDB', 'Linux', 'Python (Programming Language)', 'Haskell', 'Ingénieurs', 'Express.js', 'Web Scraping']\n",
      "[{'name': 'Neural Networks and Deep Learning', 'delivered_by': 'Coursera'}, {'name': 'Responsive Web Design', 'delivered_by': 'freeCodeCamp'}, {'name': 'Certificate of participation, OST pre-incubation program 2020', 'delivered_by': 'Open Startup'}]\n",
      "Linkedin scraping (done)\n"
     ]
    }
   ],
   "source": [
    "# Scrape the data of 1 Linkedin profile, and write the data to a .CSV file\n",
    "\n",
    "with open('output.csv', 'w',  newline = '', encoding=\"utf-8\") as file_output:\n",
    "    headers = ['Name', 'Company', 'Location','Job Title', 'Experience','Skills', 'Certificates','URL']\n",
    "    writer = csv.DictWriter(file_output, delimiter=',', lineterminator='\\n',fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "    for linkedin_URL in URLs_all_page:\n",
    "        driver.get(linkedin_URL)\n",
    "        print('Accessing profile: ', linkedin_URL)\n",
    "\n",
    "        # Get name, company, location, profile bio\n",
    "        try:\n",
    "            name = driver.find_element_by_xpath(\"//h1[@class='text-heading-xlarge inline t-24 v-align-middle break-words']\").text\n",
    "        except:\n",
    "            name = np.nan\n",
    "        \n",
    "        try:\n",
    "            company = driver.find_element_by_xpath(\"//h2[@class='text-heading-small align-self-center flex-1 break-words']//div\").text\n",
    "        except:\n",
    "            company = np.nan\n",
    "        \n",
    "        try:\n",
    "            location = driver.find_element_by_xpath(\"//span[@class='text-body-small inline t-black--light break-words']\").text\n",
    "        except:\n",
    "            location = np.nan\n",
    "            \n",
    "        try:\n",
    "            profile_bio = driver.find_element_by_xpath(\"//div[@class='text-body-medium break-words']\").text\n",
    "        except:\n",
    "            profile_bio = np.nan\n",
    "        \n",
    "        sleep(3)\n",
    "        driver.execute_script(\"window.scrollTo(0, 1000)\")\n",
    "        \n",
    "        sleep(5)\n",
    "        \n",
    "        # Get certificates\n",
    "        \n",
    "        try:\n",
    "            certificates_button = driver.find_element_by_xpath(\"//button[@class='pv-profile-section__see-more-inline pv-profile-section__text-truncate-toggle']\")\n",
    "            certificates_button.click()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        certificates_list = []\n",
    "        certificates = driver.find_elements_by_xpath(\"//div[@class='pv-profile-section__card-item']\")\n",
    "        for c in certificates:\n",
    "            certificates_details = c.text\n",
    "            \n",
    "            certificate = {\n",
    "                \"name\":certificates_details.split('\\n')[0],\n",
    "                \"delivered_by\":certificates_details.split('\\n')[2]\n",
    "            }\n",
    "            certificates_list.append(certificate)\n",
    "        \n",
    "        sleep(5)\n",
    "        \n",
    "        # Get skills\n",
    "        try:\n",
    "            show_more_skills_button = driver.find_element_by_xpath(\"//button[@class='pv-profile-section__card-action-bar pv-skills-section__additional-skills artdeco-container-card-action-bar artdeco-button artdeco-button--tertiary artdeco-button--3 artdeco-button--fluid artdeco-button--muted']\")\n",
    "            show_more_skills_button.click()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        sleep(3)\n",
    "        skills_list = []\n",
    "        skills = driver.find_elements_by_xpath(\"//span[@class='pv-skill-category-entity__name-text t-16 t-black t-bold']\")\n",
    "        for s in skills:\n",
    "            skills_list.append(s.text)\n",
    "        sleep(5)\n",
    "        \n",
    "        # Get Experience\n",
    "        experience_list = []\n",
    "        experiences = driver.find_elements_by_xpath(\"//section[@class='pv-profile-section__sortable-card-item pv-profile-section pv-position-entity ember-view']\")\n",
    "\n",
    "        for exp in experiences:\n",
    "            experience_details = exp.text\n",
    "            \n",
    "            experience = {\n",
    "                \"title\": experience_details.split('\\n')[0],\n",
    "                \"company\": experience_details.split('\\n')[2],\n",
    "                \"date\": experience_details.split('\\n')[4],\n",
    "                \"duration\": experience_details.split('\\n')[6]\n",
    "            }\n",
    "            experience_list.append(experience)\n",
    "        sleep(5)\n",
    "            \n",
    "            \n",
    "        \n",
    "        print(name)\n",
    "        print(company)\n",
    "        print(location)\n",
    "        print(profile_bio)\n",
    "        print(experience_list)\n",
    "        print(skills_list)\n",
    "        print(certificates_list)\n",
    "        \n",
    "        writer.writerow({headers[0]:name, \n",
    "                         headers[1]:company, \n",
    "                         headers[2]:location, \n",
    "                         headers[3]:profile_bio, \n",
    "                         headers[4]: experience_list,\n",
    "                         headers[5]:skills_list, \n",
    "                         headers[6]:certificates_list,\n",
    "                         headers[7]:linkedin_URL})\n",
    "    \n",
    "    print('Linkedin scraping (done)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
